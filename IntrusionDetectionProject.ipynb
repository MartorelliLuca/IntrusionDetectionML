{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c479cca",
   "metadata": {},
   "source": [
    "# Machine Learning Project: T7 - Intrusion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031bc29",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Load and preprocess the KDD dataset.\n",
    "- Train 2 machine learning models for attack classification.\n",
    "- Evaluate the models' performance using appropriate metrics.\n",
    "- Analyze the results and determine the best model for letter recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e1dddf",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28dd7f",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "1. **Dataset Loading**: Use pandas to load the EMNIST dataset.\n",
    "2. **Preprocessing**: Separate the labels from the images and reshape the images.\n",
    "3. **Model Training**: Use various machine learning techniques to train the models.\n",
    "4. **Evaluation**: Use performance metrics such as accuracy to evaluate the models.\n",
    "5. **Results Analysis**: Compare the models and select the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2c365",
   "metadata": {},
   "source": [
    "# Uploading libraries\n",
    "Let's begin to prepare all the libraries and load the dataset from the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fda9dc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 16:54:16.376388: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-02 16:54:16.391425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735833256.418059   34342 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735833256.426742   34342 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-02 16:54:16.455059: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='keras.src.trainers.data_adapters.py_dataset_adapter')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Layer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1793e10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"KDDTrainClean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46197c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.loc[df['label'] != \"normal\", \"label\"] = 'attack'\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    " \n",
    "df.head()\n",
    "# 3. Split dei dati in train e test\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8148828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creare i dati per il grafico a torta\n",
    "class_counts = df['label'].value_counts()\n",
    " \n",
    "# Creare i dati per il grafico a torta\n",
    "class_counts = df['label'].value_counts()\n",
    " \n",
    "# Grafico a torta senza spazi\n",
    "plt.figure(figsize=(8, 8))\n",
    "class_counts.plot.pie(autopct='%1.1f%%', labels=class_counts.index, colors=['skyblue', 'salmon'], startangle=90)\n",
    "plt.title(\"Distribuzione delle classi (normal vs attack)\")\n",
    "plt.ylabel(\"\")  # Rimuove l'etichetta dell'asse y\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25027233",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "sns.countplot(x='protocol_type', data=df[df['label'] == \"attack\"], hue='label', palette='husl')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribuzione degli Attacchi per Tipo di Protocollo', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Protocollo', fontsize=12)\n",
    "plt.ylabel('Conteggio', fontsize=12)\n",
    "plt.legend(title='Label', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identifica le colonne categoriali e numeriche\n",
    "categorical_cols = ['is_host_login', 'protocol_type', 'service', 'flag', 'land', 'logged_in','is_guest_login']  # Colonne categoriali\n",
    "numerical_cols = df.columns.difference(categorical_cols + ['label']).tolist()  # Colonne numeriche\n",
    " \n",
    "# 2. Encoding della colonna target\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    " \n",
    "# 3. Preprocessing delle feature\n",
    "# One-hot encoding per le colonne categoriali e scaling per quelle numeriche\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),  # Standardizzazione delle colonne numeriche\n",
    "        ('cat', OneHotEncoder(), categorical_cols)  # Encoding delle colonne categoriali\n",
    "    ]\n",
    ")\n",
    " \n",
    "X = preprocessor.fit_transform(X)\n",
    " \n",
    "# 4. Split dei dati in train e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e75df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataframe, target_column='label', categorical_cols=None, numerical_cols=None):\n",
    "    # Identify categorical and numerical columns if not provided\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = ['is_host_login', 'protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_guest_login']\n",
    "    if numerical_cols is None:\n",
    "        numerical_cols = dataframe.columns.difference(categorical_cols + [target_column]).tolist()\n",
    "    \n",
    "    # Step 1: Encoding the target column (binary classification)\n",
    "    dataframe.loc[dataframe[target_column] != \"normal\", target_column] = \"attack\"\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(dataframe[target_column])\n",
    "    \n",
    "    # Step 2: Scaling numerical columns\n",
    "    scaler = RobustScaler()\n",
    "    scaled_numerical = scaler.fit_transform(dataframe[numerical_cols])\n",
    "    scaled_df = pd.DataFrame(scaled_numerical, columns=numerical_cols)\n",
    "    \n",
    "    # Step 3: One-hot encoding categorical columns\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_categorical = encoder.fit_transform(dataframe[categorical_cols])\n",
    "    encoded_df = pd.DataFrame(encoded_categorical, columns=encoder.get_feature_names_out(categorical_cols))\n",
    "    \n",
    "    # Step 4: Combine scaled numerical and encoded categorical features\n",
    "    X = pd.concat([scaled_df.reset_index(drop=True), encoded_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    # Step 5: Split the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    " \n",
    "X_train, X_test, y_train, y_test = preprocess(df, target_column='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa98e84",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Logistic Regression\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    " \n",
    "# 6. Predizioni\n",
    "y_pred = model.predict(X_test)\n",
    " \n",
    "# 7. Valutazione del modello\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480493af",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df864bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Gestione delle variabili categoriche\n",
    "# Encoding delle variabili categoriche in X\n",
    "#categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
    "#X = pd.get_dummies(X, columns=categorical_columns)\n",
    " \n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), categorical_cols)  # Encoding delle colonne categoriali\n",
    "    ]\n",
    ")\n",
    "# Encoding dei target in y\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    " \n",
    "# 6. Split dei dati in train e test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    " \n",
    "# 7. Creazione e allenamento del Decision Tree\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "# 8. Valutazione sul test set\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
